{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "from tenacity import retry, stop_after_attempt, wait_chain, wait_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_chain(*[wait_fixed(3) for i in range(3)] +\n",
    "                       [wait_fixed(5) for i in range(2)] +\n",
    "                       [wait_fixed(10)]))\n",
    "def completion_with_backoff(**kwargs):\n",
    "    return openai.Completion.create(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_test = []\n",
    "datas = json.loads(open(\"./knowledge.json\", \"r\").read())\n",
    "for data in datas:\n",
    "    if data['task'] != 'siqa':\n",
    "        continue\n",
    "    social_test.append(data)\n",
    "print(\"len csqa-dev:\", len(social_test))\n",
    "print(social_test[0].keys())\n",
    "print(social_test[0][\"query\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_original_direct = open('prompt_original_direct.txt').read()\n",
    "print(prompt_original_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "davinci_response_list = [] \n",
    "acc = 0\n",
    "total = 0\n",
    "answer_id = [\"A\", \"B\", \"C\"]\n",
    "for mention_idx, mention in tqdm(enumerate(social_test), total=len(social_test)):\n",
    "    # answer_gold = mention[\"answerKey\"].lower()\n",
    "    answer = mention[\"answer\"]\n",
    "    prompt_q  = prompt_original_direct + \"\\nQ: \" + mention[\"query\"].split('\\\\n')[0]+ \"\\n\"\n",
    "    # prompt_q += \"Answer Choices:\\n\"\n",
    "    for idx, c in enumerate(mention[\"cands\"]):\n",
    "        if answer == c:\n",
    "            answer_gold = answer_id[idx]\n",
    "        prompt_q += '(%c) %s\\n' % (answer_id[idx], c)\n",
    "    prompt_q += mention[\"query\"].split('\\\\n')[-1].strip()\n",
    "    prompt_q += \"\\nThe answer is \"\n",
    "    # print(prompt_q)\n",
    "#     break\n",
    "    while True:\n",
    "        try:\n",
    "            response = completion_with_backoff(model=\"davinci\", \n",
    "                                                prompt=prompt_q, \n",
    "                                                temperature=0, \n",
    "                                                max_tokens=5,\n",
    "                                            )\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(3)\n",
    "    davinci_response_list.append(response)\n",
    "    answer_pred = response[\"choices\"][0][\"text\"].strip().split(\"(\")\n",
    "    answer_pred = answer_pred[1][0] if len(answer_pred) > 1 else \"a\"\n",
    "    acc += 1 if answer_pred == answer_gold else 0\n",
    "    total += 1\n",
    "    if total%50 ==0:\n",
    "        print('Total %d correct %d acc %.4f' % (total , acc , acc / total))\n",
    "#         print(\"gold:\", answer_gold)\n",
    "#         print(\"pred:\", answer_pred)\n",
    "#         print(\"acc:\", acc)\n",
    "#         print(\"total:\", total)\n",
    "#         print(prompt_q)\n",
    "#         print(response)\n",
    "#         break\n",
    "\n",
    "print('Total %d correct %d acc %.4f' % (total , acc , acc / total))\n",
    "\n",
    "# Total 1221 correct 547 acc 0.4480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_original_with_knowledge_before = open('prompt_original_with_knowledge.txt').read()\n",
    "print(prompt_original_with_knowledge_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "davinci_response_list = [] \n",
    "acc = 0\n",
    "total = 0\n",
    "answer_id = [\"A\", \"B\", \"C\"]\n",
    "for mention_idx, mention in tqdm(enumerate(social_test), total=len(social_test)):\n",
    "    answer = mention[\"answer\"]\n",
    "    prompt_q  = prompt_original_with_knowledge_before + \"\\nQ: \" + mention[\"query\"].split('\\\\n')[0]+ \"\\n\"\n",
    "    # prompt_q += \"Answer Choices:\\n\"\n",
    "    for idx, c in enumerate(mention[\"cands\"]):\n",
    "        if answer == c:\n",
    "            answer_gold = answer_id[idx]\n",
    "        prompt_q += '(%c) %s\\n' % (answer_id[idx], c)\n",
    "    prompt_q += mention[\"query\"].split('\\\\n')[-1].strip()\n",
    "    prompt_q += \"A:\"\n",
    "    # prompt_q += \"\\nThe answer is \"\n",
    "    # print(prompt_q)\n",
    "#     break\n",
    "    while True:\n",
    "        try:\n",
    "            response = completion_with_backoff(model=\"davinci\", \n",
    "                                                prompt=prompt_q, \n",
    "                                                temperature=0, \n",
    "                                                max_tokens=5,\n",
    "                                            )\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(3)\n",
    "    davinci_response_list.append(response)\n",
    "    answer_pred = response[\"choices\"][0][\"text\"].strip().split(\"(\")\n",
    "    answer_pred = answer_pred[1][0] if len(answer_pred) > 1 else \"a\"\n",
    "    acc += 1 if answer_pred == answer_gold else 0\n",
    "    total += 1\n",
    "    if total%50 ==0:\n",
    "        print('Total %d correct %d acc %.4f' % (total , acc , acc / total))\n",
    "#         print(\"gold:\", answer_gold)\n",
    "#         print(\"pred:\", answer_pred)\n",
    "#         print(\"acc:\", acc)\n",
    "#         print(\"total:\", total)\n",
    "#         print(prompt_q)\n",
    "#         print(response)\n",
    "#         break\n",
    "\n",
    "print('Total %d correct %d acc %.4f' % (total , acc , acc / total))\n",
    "\n",
    "# Total 1221 correct 547 acc 0.4480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_original_simple_instruct = open('prompt_original_simple_instruct.txt').read()\n",
    "print(prompt_original_simple_instruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "davinci_response_list = [] \n",
    "acc = 0\n",
    "total = 0\n",
    "answer_id = [\"A\", \"B\", \"C\"]\n",
    "for mention_idx, mention in tqdm(enumerate(social_test), total=len(social_test)):\n",
    "    answer_gold = mention[\"answerKey\"].lower()\n",
    "    # answer = mention[\"answerKey\"]\n",
    "    prompt_q  = prompt_original_simple_instruct + \"\\nQ: \" + mention[\"question\"][\"stem\"] + \"\\n\"\n",
    "    prompt_q += \"Answer Choices:\\n\"\n",
    "    for idx, c in enumerate(social_test[0][\"question\"][\"choices\"]):\n",
    "        prompt_q += '(%c) %s\\n' % (answer_id[idx], c[\"text\"])\n",
    "    prompt_q += \"\\nA:\"\n",
    "#     break\n",
    "    while True:\n",
    "        try:\n",
    "            response = completion_with_backoff(model=\"davinci\", \n",
    "                                                prompt=prompt_q, \n",
    "                                                temperature=0, \n",
    "                                                max_tokens=80,\n",
    "                                            )\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(3)\n",
    "    davinci_response_list.append(response)\n",
    "    answer_pred = response[\"choices\"][0][\"text\"].strip().split(\"(\")\n",
    "    answer_pred = answer_pred[1][0] if len(answer_pred) > 1 else \"a\"\n",
    "    acc += 1 if answer_pred == answer_gold else 0\n",
    "    total += 1\n",
    "    if total%50 ==0:\n",
    "        print('Total %d correct %d acc %.4f' % (total , acc , acc / total))\n",
    "#         print(\"gold:\", answer_gold)\n",
    "#         print(\"pred:\", answer_pred)\n",
    "#         print(\"acc:\", acc)\n",
    "#         print(\"total:\", total)\n",
    "#         print(prompt_q)\n",
    "#         print(response)\n",
    "#         break\n",
    "\n",
    "print('Total %d correct %d acc %.4f' % (total , acc , acc / total))\n",
    "\n",
    "# Total 1221 correct 547 acc 0.4480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_original = open('prompt_original.txt').read()\n",
    "print(prompt_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "davinci_response_list = [] \n",
    "acc = 0\n",
    "total = 0\n",
    "answer_id = [\"A\", \"B\", \"C\"]\n",
    "for mention_idx, mention in tqdm(enumerate(social_test), total=len(social_test)):\n",
    "    answer = mention[\"answer\"]\n",
    "    prompt_q  = prompt_original + \"\\nQ: \" + mention[\"query\"].split('\\\\n')[0]+ \"\\n\"\n",
    "    # prompt_q += \"Answer Choices:\\n\"\n",
    "    for idx, c in enumerate(mention[\"cands\"]):\n",
    "        if answer == c:\n",
    "            answer_gold = answer_id[idx]\n",
    "        prompt_q += '(%c) %s\\n' % (answer_id[idx], c)\n",
    "    prompt_q += mention[\"query\"].split('\\\\n')[-1].strip()\n",
    "    prompt_q += \"\\nA:\"\n",
    "    # print(prompt_q)\n",
    "    while True:\n",
    "        try:\n",
    "            response = completion_with_backoff(model=\"davinci\", \n",
    "                                                prompt=prompt_q, \n",
    "                                                temperature=0, \n",
    "                                                max_tokens=80,\n",
    "                                            )\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(3)\n",
    "    davinci_response_list.append(response)\n",
    "    answer_pred = response[\"choices\"][0][\"text\"].strip().split(\"(\")\n",
    "    answer_pred = answer_pred[1][0] if len(answer_pred) > 1 else \"a\"\n",
    "    acc += 1 if answer_pred == answer_gold else 0\n",
    "    total += 1\n",
    "    if total%50 ==0:\n",
    "        print('Total %d correct %d acc %.4f' % (total , acc , acc / total))\n",
    "print('Total %d correct %d acc %.4f' % (total , acc , acc / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "T-Patcher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
